# -*- coding: utf-8 -*-
"""perceptron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CH5c43B85APcLXfIk5gLUfVZZKoGyEyJ
"""

# Universidad Nacional Autónoma de México
# Facultad de Ingeniería

# Aguilar Enriquez Paul Sebastian 
# Cabrera Lopez Oscar Emilio 

# Reconocedor de letras

import numpy as np
from math import exp

class FullyConnectedLayer:
    """
        Capa de perceptrones
        transfer_function: funcion de transferencia, debe devolver un solo numero
        size: tamaño de la capa (# de neuronas, # de entradas)
        w: una matriz de pesos
    """
    def __init__(self, transfer_function, size=(1,1), w=None):
        self.inputs = size[1] # + 1 # inputs + bias
        self.neurons = size[0]
        if w is None:
            self.w = np.random.random(size=size)
        else:
            self.w = np.asfarray(w)
        self.b = np.ones(self.neurons)
        self.tf = np.vectorize(transfer_function, otypes=[float])

    def eval(self, inputs):
        n = np.dot(self.w, inputs) + self.b
        return self.tf(n)

class TransferFunctions:

    @staticmethod
    def linear(x):
        return x

    @staticmethod
    def satlinear(x):
        if x < 0:
            return 0
        elif x > 1:
            return 1
        else:
            return x

    @staticmethod
    def hardlim(x):
        return 0 if x < 0 else 1
        
    @staticmethod
    def hardlims(x):
        return -1 if x < 0 else 1

    @staticmethod
    def sigmoid(x):
        if x >= 0:
            z = exp(-x)
            return 1 / (1 + z)
        else:
            z = exp(x)
            return z / (1 + z)

    @staticmethod
    def tanh(x):
        if x >= 0:
            z= exp(2*x)
            return (1 - z)/(1 + z)
        else:
            z = exp(2*x)
            (z - 1)/(z + 1)

class NeuralNetworkTrainer:
    def __init__(self, net, X, Y, train_ratio=0.7, threshold=0.01, epochs=10):
        self.net = net
        self.data = {}
        self._data_divide(np.asfarray(X), np.asfarray(Y), train_ratio)
        self.error = 1
        self.data_ratio=train_ratio
        self.threshold = threshold # Umbral de error
        self.epochs = epochs

    def _data_divide(self, X, Y, ratio):
        idx = int(len(X)*ratio)
        self.data["train_X"] = X[0:idx]
        self.data["train_Y"] = Y[0:idx]
        self.data["test_X"]  = X[idx:]
        self.data["test_Y"]  = Y[idx:]
        print(self.data["train_X"])
        print(self.data["train_Y"])


    def train(self):
        epochs = 0
        while self.error > self.threshold and self.epochs > epochs:
            net_error = [] # Error de toda la red durante el epoch
            for p, t in zip(self.data["train_X"], self.data["train_Y"]):
                a = self.net.eval(p)
                error = t - a

                net_error.append(error)

# Ajuste de pesos y bias
                self.net.w += np.dot(np.reshape(error, (1, error.size)).T, np.reshape(p, (1, p.size)))
                self.net.b += error

            # Error promedio en todo el epoch
            self.error = np.average(np.abs(net_error))
            print(f"Epoch: {epochs} Error: {self.error}")
            epochs += 1

    """
    test: Evalua la red en el set de pruebas

    return(tuple):
        - (np.array): una matrix con los errores de cada neuronas en cada uno de los ejemplos
        - (float): el error promedio
    """
    def test(self):
        a, error = [], []
        for p, t in zip(self.data["test_X"], self.data["test_Y"]):
            o = net.eval(p)
            a.append(o)
            error.append(t - o)
        return error, np.average(error)

#entradas de una compuerta
X= [#entrenamiento
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1],
    #pruebas
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]]

#Salidas de una AND, OR y NAND
Y= [
    #entrenamiento
    [0, 0, 1],
    [0, 1, 1],
    [0, 1, 1],
    [1, 1, 0],
    #pruebas
    [0, 0, 1],
    [0, 1, 1],
    [0, 1, 1],
    [1, 1, 0]]

net = FullyConnectedLayer(TransferFunctions.hardlim, size=(3, 2))

trainer = NeuralNetworkTrainer(net, X, Y, train_ratio=0.5, threshold=0.0, epochs=10000)

trainer.train()

trainer.test()

net.w